<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>ADMarker CUHK</title>
  <link rel="stylesheet" href="./AD-files/bootstrap.min.css">
  <link rel="stylesheet" href="./AD-files/temp.css">
  <link rel="stylesheet" href="./AD-files/MalleConv_style.css">
  <link href="./images/CUHK.png" rel="icon">
</head>

<body data-gr-c-s-loaded="true" data-new-gr-c-s-check-loaded="14.1043.0" data-gr-ext-installed="">

<div class="container">
  <table border="0" align="center">
    <tbody><tr>
      <td width="1500" height="200" align="center" valign="middle">
      <span class="title"><h1>Machine Learning Technologies for Advancing Digital Biomarkers for Alzheimer's Disease</h1></td>
    </tr>
      
      <tr><td align="center"><h4> <a href="http://aiot.ie.cuhk.edu.hk/">Embedded AI and IoT Lab</a> </td></tr>

        <tr><td align="center"><h4> The Chinese University of Hong Kong</td></tr>
        
      <!--<div id="mit-div">
        <h4> <a href="http://aiot.ie.cuhk.edu.hk/">Embedded AI and IoT Lab</a>
        <br/>
        The Chinese University of Hong Kong
      </div>
        <td align="center"><h4> <a href="http://aiot.ie.cuhk.edu.hk/">CUHK AIoT Lab</a></td> <!--  , &nbsp;  UT Austin </h4> </td>-->
    <!-- <tr></tr>-->

  </tbody></table>
  
  <br>
  
  <p><img src="./AD-files/ADMarker-overview.png" style="margin:auto;max-width:90%" align="middle"></p>
  
  <div class="text" style="text-align: left;">
      <h2>Overview</h2>
      <p>Alzheimer’s Disease (AD) and related dementia are a growing global health challenge due to the aging population. A major barrier to the treatment of AD is that many patients are either not diagnosed or diagnosed at the late stages of the disease. A recent major advance in early AD diagnosis and intervention is to leverage AI and sensor devices to capture physiological, behavioral, and lifestyle symptoms of AD (e.g., activities of daily living and social interactions) in natural home environments, referred to as <i>digital biomarkers</i>. In this project, we propose the first end-to-end system that integrates multi-modal sensors and federated learning algorithms for detecting multidimensional AD digital biomarkers in natural living environments. We develop a compact multi-modality hardware system that can function for up to months in home environments to detect digital biomarkers of AD. On top of the hardware system, we design a multi-modal federated learning system that can accurately detect more than 20 digital biomarkers in a real-time and privacy-preserving manner. Our approach collectively addresses several major real-world challenges, such as limited data labels, data heterogeneity, and limited computing resources. </p>
    <!--We address several practical challenges to make the hardware system durable, power-efficient, and privacy-preserving.-->
    <p> <b>Patient Recruitment and Results</b>: To date, our system has been deployed in a four-week clinical trial involving 61 elderly participants (29 females and 32 males, 62 - 90 years old). The participants were from three groups: 18 with Alzheimer’s Disease, 16 with mild cognitive impairment (MCI), and 27 are cognitively normal. The results indicate that our system can accurately detect a comprehensive set of digital biomarkers with up to 95% accuracy and identify AD with an average of 87.5% accuracy. Our system offers a new platform that can allow AD clinicians to characterize and track the complex correlation between multidimensional interpretable digital biomarkers, demographic factors of patients, and AD diagnosis in a longitudinal manner.  </p>
    
    <p> <b>Ethics</b>: All the data collection in this study was approved by the Institutional Review Board of CUHK, and Clinical Research Ethics Committee of Joint CUHK and Hong Kong Hospital Authority (New Territories East Cluster).</p>
  </div>
  
 </div>

<br>
 

<div class="container">
  <h2>People</h2>
    <div class="overview">
    <p>
      <p> <li> Professors: <a href="https://staff.ie.cuhk.edu.hk/~glxing/">Guoliang Xing</a> (PI, Professor, CUHK), <a href="https://www.mect.cuhk.edu.hk/people/timothykwok.html">Timothy CY Kwok</a> (co-PI, Professor, CUHK), <a href="https://nursing.hku.hk/people/research-faculty/sau-fung-yu/">Doris Sau Fung YU</a> (co-PI, Professor, HKU), <a href="https://www.psychiatry.cuhk.edu.hk/members/dr-allen-lee/">Allen Ting Chun Lee</a> (co-PI, Assistant Professor, CUHK), <a href="https://www.ie.cuhk.edu.hk/people/yychan.shtml">Rosanna Yuen-Yan Chan</a> (Assistant Professor, CUHK), <a href="https://boleizhou.github.io/">Bolei Zhou</a> (Assistant Professor, UCLA), <a href="https://yanzhenyu.com/">Zhenyu Yan</a> (Research Assistant Professor, CUHK) </li></p>
      <p> <li> Students and Postdocs: <a href="https://xmouyang.github.io/">Xiaomin Ouyang</a> (Ph.D candidate, CUHK, Team Leader), <a href="https://sxontheway.github.io/">Xian Shuai</a> (Ph.D, 2022, CUHK), Yang Li (Ph.D student, CUHK), Li Pan (Research Assitant, CUHK), Xifan Zhang (Ph.D student, CUHK), Heming Fu (Research Assitant, CUHK), Sitong Cheng (Research Assitant, CUHK), Xinyan Wang (Undergraduate Student Helper, CUHK), Heming Fu (Research Assitant, CUHK), Shihua Cao (Postdoc Researcher, CUHK), Hazel Mok (Postdoc Researcher, CUHK) </li></p>
    </p>
    </div>
</div>
  
<br> 


<div class="container">
  
  <div class="text" style="text-align: left;">
      <h2>Research Thrusts</h2>
      
    <p> </p>
      <p> <b> 1. System Design. </b> We develop a compact multi-modality hardware system that can function for up to months in home environments to detect digital biomarkers of AD. It incorporates three privacy-preserving sensors (a depth camera, a mmWave radar, and a microphone), an NVIDIA single-board edge computer, and a 4G cellular interface that can communicate with the server. 
    </p>
    
    <p>The goal of the hardware design is to capture lots of digital biomarkers in a privacy-preserving manner while ensuring the durability and scalability of the system. To this end, we choose three privacy-preserving sensor modalities: a depth camera, a mmWave radar, and a microphone. In particular, the Time-of-Flight (ToF) depth camera cannot reveal sensitive personal information like faces; the mmWave radar can only detect the motions of the subjects; the ambient microphones run real-time algorithms to extract acoustic features without recording any raw acoustic data. Collectively, the three sensor modalities can collectively capture a wide range of biomarkers such as having meals, conversations, watching TV, etc. Moreover, the hardware nodes are incorporated with a cellular interface to communicate with the server located in our lab using 4G LTE through a Virtual Private Network (VPN). A major challenge of continuous training with all of the collected sensor data in online FL is the significant training delay. We apply several data reduction strategies to reduce the model training delay in continuous multi-modal FL without significantly sacrificing the data quality. In order to capture the main living area of a living room, we put the node at the height of 1.5m-1.8m (typically on the shelf or cabinet around the sofa), and use the tripod to adjust the height and angle of the box. The installation process typically takes about ten minutes per home. </p>
  
  </div>
  
     <p> </p>
  
      <p><img src="./AD-files/system-design.png" style="margin:auto;max-width:95%" align="middle"></p>
  
    <div class="text" style="text-align: left;">
      <p> <b> 2. Contrastive Fusion Learning for Multi-Modal Activity Recognition with Small Data.</b> Multi-modal sensing systems are essential for capturing complex and dynamic human activities such as conversation and family meals, which are important digital biomarkers for Alzheimer's disease. However, fusing multiple sensor modalities in human activity recognition (HAR) applications presents several major challenges. First, there usually exists a very limited amount of labeled data, as it is difficult to label multi-modal data in real-world settings. Second, different types of sensors usually produce highly heterogeneous information about the same events/activities, making it challenging to extract useful information for efficient fusion. Third, the sensor data in HAR applications is often privacy-sensitive and changing over time, which requires on-device training using continuous multimodal data. </p>
      
       <p> We propose <a href="https://dl.acm.org/doi/pdf/10.1145/3495243.3560519"> Cosmo </a> to address such challenges, which is a new system for contrastive fusion learning with small data in multi-modal HAR applications. Cosmo features a novel two-stage training strategy that leverages both unlabeled data on the cloud and limited labeled data on edge. In the first stage, Cosmo employs a novel fusion-based contrastive learning approach to train the feature encoders using unlabeled multimodal data. As a result, Cosmo can extract consistent information that represents the common knowledge shared among different modalities. In the second stage, a new quality-guided attention mechanism is designed to allow the classifier to capture the strengths of different modalities based on only limited labeled data, which explores the complementary information of different modalities. By integrating a novel iterative fusion learning algorithm, Cosmo can effectively combine both consistent and complementary information across different modalities for efficient fusion. Our evaluation on a cloud-edge testbed using three real-world multi-modal HAR datasets shows that Cosmo significantly improves over state-of-the-art baselines in recognition accuracy and convergence delay. For example, Cosmo can achieve about 90% recognition accuracy with only 400 labeled data samples. </p>
   </div>
  
    <p><img src="./AD-files/cosmo.png" style="margin:auto;max-width:65%" align="middle"></p>
  
  <div class="text" style="text-align: left;">
      <p> <b> 3. Federated Learning Systems for Privacy-Preserving Activity Recognition. </b> Most of the previous activity recognition studies are focused on the centralized learning approach that needs to be trained centrally using all the data collected from users. However, collecting sensor data centrally imposes significant privacy concerns for applications like longitudinal chronic condition monitoring. Federated learning (FL) is a distributed machine learning approach, which only requires the nodes to upload model weights to avoid exposing users’ raw data during the learning process.</p>
    
   <p>  Existing FL paradigms yield unsatisfactory performance for real-world activity recognition in Alzheimer’s patient monitoring. First, different subjects usually have highly heterogeneous data distributions. For example, AD patients and cognitively normal subjects exhibit highly different behavior patterns, resulting in non-i.i.d. data distributions among nodes. We find that, in spite of the heterogeneity, data distributions of different subjects’ activities may share significant spatial-temporal similarity. Motivated by this key observation, we propose <a href="https://dl.acm.org/doi/pdf/10.1145/3458864.3467681">ClusterFL </a>, a similarity-aware federated learning system that can provide high model accuracy and low communication overhead. ClusterFL features a novel clustered multi-task federated learning framework that maximizes the training accuracy of multiple learned models while automatically capturing the intrinsic clustering relationship among the data of different nodes. Second, in both local and global views, the distribution of different activities usually yields a long tail effect, where some activities such as “sitting” incur frequently, and others like “writing” appear rarely. We propose <a href="https://dl.acm.org/doi/pdf/10.1145/3458864.3467681">BalanceFL </a>, a federated learning framework that can robustly learn both common and rare classes from long-tailed real-world data. Instead of letting nodes upload biased local models trained on imbalanced private data, we design a new local self-balancing scheme, which forces the uploaded local model to behave as if it were trained from a uniform distribution dataset with the help of the aggregated global model. Extensive experiments on an NVIDIA edge FL testbed using real-world HAR datasets show our approach can acheive high model accuracy and low communication latency. </p>
  
 </div>
  
    <p><img src="./AD-files/fl-system.png" style="margin:auto;max-width:90%" align="middle"></p>
  
   </div>


<div class="container">
  <h2>Major Publications</h2>
    <div class="overview">
    <p>
     <p> 1. Xiaomin Ouyang, Xian Shuai, Jiayu Zhou, Ivy Wang Shi, Zhiyuan Xie, Guoliang Xing, Jianwei Huang, "Cosmo: Contrastive Fusion Learning with Small Data for Multimodal Human Activity Recognition", The 28th Annual International Conference on Mobile Computing and Networking (MobiCom), 2022, acceptance ratio: 56/317=17.7%.</p>
     <p> 2. Xiaomin Ouyang, Zhiyuan Xie, Jiayu Zhou, Jianwei Huang, Guoliang Xing, "ClusterFL: A Similarity-Aware Federated Learning System for Human Activity Recognition", The 19th Annual International Conference on Mobile Systems, Applications, and Services (MobiSys), 2021, acceptance ratio: 36/166=21.6%. </p>
     <p> 3. Linlin Tu, Xiaomin Ouyang, Jiayu Zhou, Yuze He, Guoliang Xing, "FedDL: Federated Learning via Dynamic Layer Sharing for Human Activity Recognition", The 19th ACM Conference on Embedded Networked Sensor Systems (SenSys), 2021, acceptance ratio: 25/139=17.98%. </p>
      <p> 4. Xian Shuai, Yulin Shen, Siyang Jiang, Zhihe Zhao, Zhenyu Yan, Guoliang Xing, "BalanceFL: Addressing Class Imbalance in Long-Tail Federated Learning", The 21st ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN), 2022, acceptance ratio: 38/126=30.2%.</p>
    </p>
    </div>
</div>

<br> 

  
<div class="container">
  <h2>Funding</h2>
    <div class="overview">
    <p>
     <p> 1. <a href="https://www.alzdiscovery.org/">Alzheimer’s Drug Discovery Foundation (ADDF)</a>, “<a href="https://www.alzdiscovery.org/research-and-grants/portfolio-details/21130887">Machine Learning Technologies for Advanced Digital Biomarkers for Alzheimer's Disease</a>”, PI, HKD $5,560,354, 2021-2023.</p>
     <p> 2. Collaborative Research Fund, "Small Data Learning for Alzheimer's Disease: From Digital Biomarker to Personalized Intervention", PI, HKD $8,230,720, 2022-2025.</p>
     <p> 3. RGC Research Grant General Research Fund, "HomeSense: A Pervasive System for Home Activity Recognition via Federated Learning", PI, HKD $1,045,055, 2021-2023.</p>
    </p>
    </div>
</div>

<br>

</p></div></div><br>

</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
